{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying handwritten digits from the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from six.moves import urllib\n",
    "random.seed(42)    #42, Answer to the Ultimate Question of Life, the Universe, and Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://github.com/amplab/datascience-sp14/raw/master/lab7/mldata/mnist-original.mat\"\n",
    "PATH = os.path.join('datasets', 'mnist')\n",
    "def fetch_data(url=URL, path=PATH):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "    file_path = os.path.join(path, url.split('/')[-1])\n",
    "    urllib.request.urlretrieve(url, file_path)\n",
    "    return file_path\n",
    "file_path = fetch_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "mnist = scipy.io.loadmat(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist['target'] = mnist.pop('label')    #to match the key name used when downlaoded by sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: (70000, 784)\n",
      "Target: (70000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X, y = np.transpose(mnist['data']), np.reshape(mnist['target'], np.product(mnist['target'].shape),)\n",
    "\n",
    "print(\"Data:\", X.shape)\n",
    "print(\"Target:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a peek at one digit from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rand = random.randint(0, 69999)\n",
    "some_digit = X[rand]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "plt.imshow(some_digit_image, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "plt.title(y[rand])\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "\n",
    "### The MNIST dataset is actually already split (60,000 + 10,000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffling the training set\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Binary Classifier (simplifying the problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abandoned_greyhound/env/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a \"5-detector\"\n",
    "y_train_5 = (y_train == 5)\n",
    "y_test_5 = (y_test == 5)\n",
    "\n",
    "#running a Stochastic Gradient Descent Classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.predict([X[36000]])    #image of a '5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measures\n",
    "\n",
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abandoned_greyhound/env/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abandoned_greyhound/env/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abandoned_greyhound/env/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9651\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=3, random_state=42)\n",
    "\n",
    "for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
    "    clone_clf = clone(sgd_clf)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = y_train_5[train_index]\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = y_train_5[test_index]\n",
    "    \n",
    "    clone_clf.fit(X_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(n_correct / len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abandoned_greyhound/env/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/abandoned_greyhound/env/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/abandoned_greyhound/env/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.96745, 0.9604 , 0.9651 ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using the cross_val_score() function\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
